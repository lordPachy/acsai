{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filters\n",
    "They are a single application applied to the entire image, and they serve various purposes.\n",
    "They are usually needed in order to highlight a feature in the image."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Essentially, a filter is a matrix, called **kernel** that is applied to every single pixel in the image.  \n",
    "A different value of the **stride** can make it apply on a fraction of the pixels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "img = cv2.imread(\"samples/tree.png\")\n",
    "#cv2.imshow(\"Original\", img)\n",
    "#cv2.waitKey(0)\n",
    "#cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is strongly suggested to use *odd-sized* (square) kernels, because they have a well - defined \"center\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel = np.array([\n",
    "    [1, 0, 1],\n",
    "    [1, 0, 1],\n",
    "    [1, 0, 1]\n",
    "], np.float32)\n",
    "#Applying kernel\n",
    "filtered = cv2.filter2D(img, -1, kernel)\n",
    "#filter2D is the method for applying this kind of transformations.\n",
    "#the second parameter is the number of channels we want in the output image:\n",
    "#-1 sets it to the number of channels of the original image\n",
    "#This is because if we want to apply the kernel to be applied to every channel,\n",
    "#It must be specified.\n",
    "\n",
    "cv2.imshow(\"Filtered\", filtered)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Blur\n",
    "\n",
    "It is useful to *denoise* an image, since it averages the values accross pixels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "blurred = cv2.blur(img, (10, 10), None)\n",
    "cv2.imshow(\"Blurred\", blurred)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The second parameter of `blur` is the dimension of the kernel. The bigger the kernel, the more blurred the image will be."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gaussian blur\n",
    "\n",
    "It assumes a gaussian distribution of the noise, and the kernel is arranged accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "gaussian_blurred = cv2.GaussianBlur(img, (3, 3), 1)\n",
    "cv2.imshow(\"Blurred\", gaussian_blurred)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`sigmaX` and `sigmaY` set the standard deviation of the noise (kernel).  \n",
    "Setting a single value is giving the same value to both parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Median blur\n",
    "\n",
    "The so-called *salt and pepper noise* is a kind of noise that can be removed through this filter.  \n",
    "It is made up of completely white and black pixels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "saltpepper = cv2.imread(\"samples/saltpepper.jpeg\")\n",
    "median_blur = cv2.medianBlur(saltpepper, 5, None)\n",
    "cv2.imshow(\"Blurred\", median_blur)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, there is a single value in the `medianBlur` method since the kernel **must** be square."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bilateral filter\n",
    "\n",
    "This keeps the edges sharp while still applying some noise reduction inside shapes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "bilateraled = cv2.bilateralFilter(img, 9, 75, 75)\n",
    "cv2.imshow(\"Blurred\", bilateraled)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parameters???"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sharpening"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sharpen mask\n",
    "\n",
    "It sums the original with a blurred version in order to sharpen the edges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(\"samples/tiger.jpg\")\n",
    "blurred = cv2.GaussianBlur(img, (7, 7), 10)\n",
    "sharped_img = cv2.addWeighted(img, 0.7, blurred, 0.3, 0)\n",
    "cv2.imshow(\"Sharpen mask\", sharped_img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`addWeighted` performs a weighted mean of the two images. The last parameter performs some color correction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sharpen kernel\n",
    "\n",
    "It just applies a well-known kernel to sharpen it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel = np.array([\n",
    "    [0, -1, 0],\n",
    "    [-1, 5, -1],\n",
    "    [0, -1, 0]\n",
    "], np.float32)\n",
    "\n",
    "sharpened = cv2.filter2D(img, -1, kernel)\n",
    "cv2.imshow(\"Kernel sharpening\", sharpened)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Derivative - based filters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sobel operator\n",
    "\n",
    "Contours can be interpreted as sharp changes, and if we treat pixel as functions, they can be detected via derivatives. There are 2 derivatives (one for the x - axis, and one for the y - axis). To do it, it is sufficient to transpose the kernel.  \n",
    "Once the partial derivatives are calculated, they can be combined into a single gradient.  \n",
    "Since every pixel ranges in $[0, 255]$, they must also be normalized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#First of all, let's convert the image to greyscale\n",
    "img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "der_x = cv2.Sobel(img_gray, -1, 1, 0)\n",
    "der_y = cv2.Sobel(img_gray, -1, 0, 1)\n",
    "\n",
    "scaled_x = cv2.convertScaleAbs(der_x)\n",
    "scaled_y = cv2.convertScaleAbs(der_y)\n",
    "'''\n",
    "cv2.imshow(\"Scaled-x\", scaled_x)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "cv2.imshow(\"Scaled-y\", scaled_y)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "'''\n",
    "\n",
    "out = cv2.addWeighted(scaled_x, 0.5, scaled_y, 0.5, 0)\n",
    "cv2.imshow(\"Total\", out)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The last two arguments are booleans expressing which derivative we are taking. They can be easily combined with a weighted average."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Laplacian filter\n",
    "\n",
    "It applies twice the Sobel operator, thus providing a second-derivative overview of the \"zero\" points.  \n",
    "Consequently, it also contains all the borders extracted by the Sobel operator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "der = cv2.Laplacian(img_gray, -1, (3, 3))\n",
    "\n",
    "cv2.imshow(\"Total\", der)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A cartoonized filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.9.0) /io/opencv/modules/imgproc/src/color.simd_helpers.hpp:92: error: (-2:Unspecified error) in function 'cv::impl::{anonymous}::CvtHelper<VScn, VDcn, VDepth, sizePolicy>::CvtHelper(cv::InputArray, cv::OutputArray, int) [with VScn = cv::impl::{anonymous}::Set<1>; VDcn = cv::impl::{anonymous}::Set<3, 4>; VDepth = cv::impl::{anonymous}::Set<0, 2, 5>; cv::impl::{anonymous}::SizePolicy sizePolicy = cv::impl::<unnamed>::NONE; cv::InputArray = const cv::_InputArray&; cv::OutputArray = const cv::_OutputArray&]'\n> Invalid number of channels in input image:\n>     'VScn::contains(scn)'\n> where\n>     'scn' is 3\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[46], line 20\u001b[0m\n\u001b[1;32m     18\u001b[0m colours \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mbilateralFilter(img, \u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m250\u001b[39m, \u001b[38;5;241m250\u001b[39m)\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m#converting the gray edges image into a 3-channel image\u001b[39;00m\n\u001b[0;32m---> 20\u001b[0m edges \u001b[38;5;241m=\u001b[39m \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcvtColor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mthresholded\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcode\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCOLOR_GRAY2BGR\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m#bitwise AND for merging edges and colours\u001b[39;00m\n\u001b[1;32m     23\u001b[0m out \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mbitwise_and(colours, img)\n",
      "\u001b[0;31merror\u001b[0m: OpenCV(4.9.0) /io/opencv/modules/imgproc/src/color.simd_helpers.hpp:92: error: (-2:Unspecified error) in function 'cv::impl::{anonymous}::CvtHelper<VScn, VDcn, VDepth, sizePolicy>::CvtHelper(cv::InputArray, cv::OutputArray, int) [with VScn = cv::impl::{anonymous}::Set<1>; VDcn = cv::impl::{anonymous}::Set<3, 4>; VDepth = cv::impl::{anonymous}::Set<0, 2, 5>; cv::impl::{anonymous}::SizePolicy sizePolicy = cv::impl::<unnamed>::NONE; cv::InputArray = const cv::_InputArray&; cv::OutputArray = const cv::_OutputArray&]'\n> Invalid number of channels in input image:\n>     'VScn::contains(scn)'\n> where\n>     'scn' is 3\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "img = cv2.imread(\"samples/tiger.jpg\")\n",
    "\n",
    "img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "#apply a light blur for cleaning the image\n",
    "img_gray = cv2.medianBlur(img, 5)\n",
    "#extract the contours\n",
    "contours = cv2.Laplacian(img_gray, cv2.CV_8U, ksize=5) #this parameter creates an 8-bit unsigned image\n",
    "# so it takes a value of grey between 0 and 255\n",
    "#applying a threshold so we can take only strong (true) edges\n",
    "ret, thresholded = cv2.threshold(contours, 70, 255, cv2.THRESH_BINARY_INV)\n",
    "#the last parameter specifies the type of colorscheme used in this image\n",
    "#THRESH_BINARY_INV has black background and white contours\n",
    "\n",
    "#using the bilateral filter with high values to get the colours:\n",
    "colours = cv2.bilateralFilter(img, 10, 250, 250)\n",
    "#converting the gray edges image into a 3-channel image\n",
    "edges = cv2.cvtColor(thresholded, code = cv2.COLOR_GRAY2BGR)\n",
    "\n",
    "#bitwise AND for merging edges and colours\n",
    "out = cv2.bitwise_and(colours, img)\n",
    "cv2.imshow(\"Cartoonized img\", out)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ailab",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
