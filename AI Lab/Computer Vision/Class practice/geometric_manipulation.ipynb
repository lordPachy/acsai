{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Geometric manipulation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upscaling and resizing\n",
    "\n",
    "It is possible to upscale, downscale and stretch images with OpenCV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "img = cv2.imread(\"samples/tree.png\")\n",
    "img = cv2.resize(img, (img.shape[1]//2, img.shape[0]//2))\n",
    "cv2.imshow(\"Downscaled image\", img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "stretched_img = cv2.resize(img, None, None, fx=3, fy=0.5)\n",
    "cv2.imshow(\"Stretched image\", stretched_img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is also possible to express the desired manipulation through a matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "M = np.float32([[0, 1, 0],\n",
    "              [1, 0, 0]])\n",
    "stretched_img = cv2.warpAffine(img, M, img.shape[:-1])\n",
    "cv2.imshow(\"Stretched image\", stretched_img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows, cols = img.shape[0], img.shape[1]\n",
    "R = cv2.getRotationMatrix2D((cols//2, rows//2), 30, 1)\n",
    "rotated_img = cv2.warpAffine(img, R, (cols, rows))\n",
    "cv2.imshow(\"Rotated image\", rotated_img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "tx = 0\n",
    "ty = 0\n",
    "t = [[1, 0, tx],\n",
    "     [0, 1, ty]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A panorama function and generic affine transformations\n",
    "\n",
    "In generic transformations, we need at least 3 points to infer the original function.  \n",
    "They preserve parallelism."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.          0.08108108 -3.64864865]\n",
      " [ 0.          1.          0.        ]]\n"
     ]
    }
   ],
   "source": [
    "pts_1 = np.float32([[135, 45],\n",
    "                    [385, 45],\n",
    "                    [135, 230]])\n",
    "\n",
    "pts_2 = np.float32([[135, 45],\n",
    "                    [385, 45],\n",
    "                    [150, 230]])\n",
    "\n",
    "M = cv2.getAffineTransform(pts_1, pts_2)    #this is an affine transformation that, given the first\n",
    "                                            #set of points, returns the second one\n",
    "panorama = cv2.warpAffine(pts_1, M, (800, 800))\n",
    "print(M)\n",
    "#cv2.imshow(\"Chosen set of points\", panorama)\n",
    "#cv2.waitKey(0)\n",
    "#cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scanner application"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First of all, we need to import the picture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(\"samples/gerry.png\")\n",
    "cv2.imshow(\"Original\", img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can take the corner coordinates:\n",
    "\n",
    "* tl - 28, 227\n",
    "* bl- 131, 987\n",
    "* tr - 572, 149\n",
    "* br - 730, 860"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_points = np.array([\n",
    "    [28, 227],\n",
    "    [131, 987],\n",
    "    [572, 149],\n",
    "    [730, 860]\n",
    "],  np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some debugging on coordinates position:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "points = img.copy()\n",
    "points = cv2.circle(points, np.asarray(src_points[3], np.int32), 10, (0, 0, 255), -1)\n",
    "\n",
    "points = cv2.resize(points, None, None, fx = 0.7, fy = 0.7)\n",
    "cv2.imshow(\"Scanned image\", points)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We want to rescale it in a 600x800 image\n",
    "dst_points = np.array(\n",
    "    [\n",
    "        [0, 0],\n",
    "        [0, 800],\n",
    "        [600, 0],\n",
    "        [600, 800],\n",
    "    ], np.float32\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the transformation matrix M: we use perspectiveTransorm since it\n",
    "#is not just an affine transformation, the contours of the image are not\n",
    "#parallel in the original\n",
    "M = cv2.getPerspectiveTransform(src_points, dst_points)\n",
    "out_img = cv2.warpPerspective(img, M, (600, 800))\n",
    "cv2.imshow(\"Scanned image\", out_img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A different implementation of the scanner\n",
    "\n",
    "Let's create an interface in order to get the starting points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Starting steps\n",
    "\n",
    "img = cv2.imread(\"samples/gerry.png\")\n",
    "img = cv2.resize(img, None, None, fx = 0.7, fy = 0.7)\n",
    "img_copy = img.copy()\n",
    "\n",
    "src_points = []\n",
    "dst_points = np.array(\n",
    "    [\n",
    "        [0, 0],\n",
    "        [0, 600],\n",
    "        [800, 0],\n",
    "        [800, 600],\n",
    "    ], np.float32\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating the window for selecting the starting points\n",
    "\n",
    "#defining the callback function on the event of clicking the left button\n",
    "def onClick(event, x, y, flags, param):\n",
    "    if event == cv2.EVENT_FLAG_LBUTTON:\n",
    "        if len(src_points) < 4:\n",
    "            src_points.append([x, y])           #pay attention to the square brackets\n",
    "            cv2.circle(img_copy, (x, y), 10, (0, 0, 255), -1)\n",
    "            cv2.imshow(\"Img\", img_copy)\n",
    "\n",
    "cv2.namedWindow('Img')\n",
    "#the next function takes input of the mouse as the callback for the previously created window\n",
    "cv2.setMouseCallback(\"Img\", onClick)\n",
    "#Show the image\n",
    "cv2.imshow(\"Img\", img_copy)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows\n",
    "\n",
    "#Compute the matrix M\n",
    "#We first need to convert the points to the correct format\n",
    "\n",
    "src_float = np.array(src_points, dtype=np.float32)\n",
    "M = cv2.getPerspectiveTransform(src_float, dst_points)\n",
    "\n",
    "#Get the final image\n",
    "out_img = cv2.warpPerspective(img, M, (800, 600))\n",
    "cv2.imshow(\"Img\", out_img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Projection\n",
    "\n",
    "A projection requires 4 points to be inferred."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ailab",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
