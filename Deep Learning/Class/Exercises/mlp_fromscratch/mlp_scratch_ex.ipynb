{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from IPython.display import clear_output\n",
    "\n",
    "%matplotlib inline\n",
    "set_seed = torch.manual_seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "fmnist = torchvision.datasets.FashionMNIST(root = \"/home/pachy/Desktop/ACSAI/acsai/Deep Learning/Class/Exercises/mlp_fromscratch/FashionMNIST\",\n",
    "                                           download = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pachy/.cache/pypoetry/virtualenvs/dlcourse-BfLxQsIA-py3.11/lib/python3.11/site-packages/torchvision/datasets/mnist.py:81: UserWarning: test_data has been renamed data\n",
      "  warnings.warn(\"test_data has been renamed data\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([60000, 28, 28])"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fmnist.test_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(torch.nn.Module):\n",
    "    def __init__(self, num_inputs, num_outputs, num_hidden_units, num_hidden_layers = 1):\n",
    "        super().__init__()\n",
    "        hiddens = [(torch.nn.Linear(num_hidden_units, num_hidden_units), torch.nn.ReLU()) for x in range(num_hidden_layers - 1)]\n",
    "        self.model = torch.nn.Sequential(torch.nn.Flatten(),\n",
    "                                        torch.nn.Linear(in_features=num_inputs, \n",
    "                                                         out_features=num_hidden_units),\n",
    "                                        torch.nn.ReLU(),\n",
    "                                        *hiddens,\n",
    "                                        torch.nn.Linear(in_features=num_hidden_units,\n",
    "                                                        out_features=num_outputs))       \n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x.to(torch.float32)\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer:\n",
    "    def __init__(self, model, loss, optimizer, batchsize = 32, epochs = 5):\n",
    "        self.model = model\n",
    "        self.loss = loss\n",
    "        self.optimizer = optimizer\n",
    "        self.epochs = epochs\n",
    "        self.batchsize = batchsize\n",
    "\n",
    "    def live_plot(self, train_loss, val_loss, val_accuracy, figsize=(7,5), title='Loss per epoch'):\n",
    "        '''\n",
    "        It plots only the average loss per epoch.\n",
    "        '''\n",
    "        train_loss = train_loss.astype('float64')\n",
    "        val_loss = val_loss.astype('float64')\n",
    "        #val_accuracy = val_accuracy.astype('float64')\n",
    "        x = np.arange(train_loss.size[0])\n",
    "\n",
    "        clear_output(wait=True)         # This is needed for live updates\n",
    "        plt.figure(figsize=figsize)\n",
    "        plt.title(title)\n",
    "        plt.grid(True)\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Loss')\n",
    "\n",
    "        plt.plot(x, train_loss, label = \"Training loss\")\n",
    "        plt.plot(x, val_loss, label = \"Validation loss\")\n",
    "        #plt.plot(x, val_accuracy, label = \"Validation accuracy\")\n",
    "        plt.show()\n",
    "        \n",
    "    def fit_model(self, training_set, training_labels, validation_set, validation_labels):\n",
    "        '''\n",
    "        A function that creates the training data,\n",
    "        optimizes the model and plots the results.\n",
    "        '''\n",
    "        \n",
    "        train_loss = np.array([])\n",
    "        val_loss = np.array([])\n",
    "        val_accuracy = np.array([])\n",
    "\n",
    "        iterations = training_set.shape[0]//self.batchsize\n",
    "\n",
    "        for i in range(self.epochs):\n",
    "            for j in range(iterations):\n",
    "                # Data loading  \n",
    "                x = training_set[j*self.batchsize:(j+1)*self.batchsize]\n",
    "                y = training_labels[j*self.batchsize:(j+1)*self.batchsize].to(torch.int64)\n",
    "\n",
    "                # Loss computation\n",
    "                self.model.train()\n",
    "                y_hat = self.model.forward(x)\n",
    "                print(y_hat[0])\n",
    "                print(f\"Prediction type is {y_hat.dtype} of shape {y_hat.shape}\")\n",
    "                print(y)\n",
    "                print(f\"Class type is {y.dtype} of shape {y.shape}\")\n",
    "                loss = self.loss(y_hat, y)\n",
    "                train_loss = np.append(train_loss, loss.detach().numpy())   # this is needed for plotting\n",
    "\n",
    "                # Optimization\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "                self.optimizer.zero_grad()\n",
    "                \n",
    "                # Validation\n",
    "                with torch.no_grad():\n",
    "                    self.model.eval()\n",
    "                    x = validation_set[j*self.batchsize:(j+1)*self.batchsize]\n",
    "                    y = validation_labels[j*self.batchsize:(j+1)*self.batchsize]\n",
    "                    y_hat = self.model.forward(x)\n",
    "                    loss = self.loss(y, y_hat)\n",
    "                    val_loss = np.append(val_loss, loss)   # this is needed for plotting\n",
    "\n",
    "                # Updating the training plot\n",
    "                self.live_plot(train_loss, val_loss, val_accuracy)        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training tests\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normal training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 35.6216, -16.5194, -58.2751,   5.3767,  17.1835, -42.3165,  49.6992,\n",
      "         63.5843,  19.6905,  -1.8996], grad_fn=<SelectBackward0>)\n",
      "Prediction type is torch.float32 of shape torch.Size([32, 10])\n",
      "tensor([9, 0, 0, 3, 0, 2, 7, 2, 5, 5, 0, 9, 5, 5, 7, 9, 1, 0, 6, 4, 3, 1, 4, 8,\n",
      "        4, 3, 0, 2, 4, 4, 5, 3])\n",
      "Class type is torch.int64 of shape torch.Size([32])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "\"log_softmax_lastdim_kernel_impl\" not implemented for 'Long'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[187], line 15\u001b[0m\n\u001b[1;32m     12\u001b[0m loss \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mfunctional\u001b[38;5;241m.\u001b[39mcross_entropy\n\u001b[1;32m     13\u001b[0m trainer \u001b[38;5;241m=\u001b[39m Trainer(model, loss, optimizer, epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m)\n\u001b[0;32m---> 15\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtraining_set\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining_labels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_set\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_labels\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[186], line 69\u001b[0m, in \u001b[0;36mTrainer.fit_model\u001b[0;34m(self, training_set, training_labels, validation_set, validation_labels)\u001b[0m\n\u001b[1;32m     67\u001b[0m     y \u001b[38;5;241m=\u001b[39m validation_labels[j\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatchsize:(j\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatchsize]\n\u001b[1;32m     68\u001b[0m     y_hat \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mforward(x)\n\u001b[0;32m---> 69\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloss\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_hat\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     70\u001b[0m     val_loss \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mappend(val_loss, loss)   \u001b[38;5;66;03m# this is needed for plotting\u001b[39;00m\n\u001b[1;32m     72\u001b[0m \u001b[38;5;66;03m# Updating the training plot\u001b[39;00m\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/dlcourse-BfLxQsIA-py3.11/lib/python3.11/site-packages/torch/nn/functional.py:3104\u001b[0m, in \u001b[0;36mcross_entropy\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction, label_smoothing)\u001b[0m\n\u001b[1;32m   3102\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m size_average \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m reduce \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   3103\u001b[0m     reduction \u001b[38;5;241m=\u001b[39m _Reduction\u001b[38;5;241m.\u001b[39mlegacy_get_string(size_average, reduce)\n\u001b[0;32m-> 3104\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_nn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcross_entropy_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_Reduction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_enum\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreduction\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel_smoothing\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: \"log_softmax_lastdim_kernel_impl\" not implemented for 'Long'"
     ]
    }
   ],
   "source": [
    "# We first need to create the dataset\n",
    "training_set = fmnist.data[:1000]\n",
    "training_labels = fmnist.targets[:1000]\n",
    "val_set = fmnist.data[-1000:]\n",
    "val_labels = fmnist.targets[-1000:]\n",
    "\n",
    "model = MLP(num_inputs=28*28,\n",
    "            num_hidden_units=256,\n",
    "            num_hidden_layers=1,\n",
    "            num_outputs=10)\n",
    "optimizer = torch.optim.SGD(params=model.parameters(), lr=0.1)\n",
    "loss = torch.nn.functional.cross_entropy\n",
    "trainer = Trainer(model, loss, optimizer, epochs=10)\n",
    "\n",
    "trainer.fit_model(training_set, training_labels, val_set, val_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training debugging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ -3.1556,  -2.7377,   9.9521,  28.6245,  11.9328,  28.8031,   2.6220,\n",
      "         43.5725,  33.5562, -16.0243])\n",
      "tensor([9, 0, 0, 3, 0, 2, 7, 2, 5, 5, 0, 9, 5, 5, 7, 9, 1, 0, 6, 4, 3, 1, 4, 8,\n",
      "        4, 3, 0, 2, 4, 4, 5, 3])\n",
      "torch.Size([32, 10]) torch.float32\n",
      "torch.Size([32]) torch.int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(42.6611)"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = 100*(torch.rand(size=(32, 10))-0.5*torch.ones(size=(32, 10))).to(torch.float32)\n",
    "print(a[0])\n",
    "lab_a = training_labels[:32]\n",
    "print(lab_a)\n",
    "\n",
    "print(a.shape, a.dtype)\n",
    "print(lab_a.shape, lab_a.dtype)\n",
    "\n",
    "debug_loss = torch.nn.CrossEntropyLoss()\n",
    "debug_loss(a, lab_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1000, 28, 28])"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_set.to(torch.float64).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = torchvision.transforms.ToPILImage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "ValueError",
     "evalue": "The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m img \u001b[38;5;241m=\u001b[39m training_set[\u001b[38;5;241m2\u001b[39m]\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[1;32m      2\u001b[0m plt\u001b[38;5;241m.\u001b[39mimshow(img)\n\u001b[0;32m----> 3\u001b[0m \u001b[43mplt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshow\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/dlcourse-BfLxQsIA-py3.11/lib/python3.11/site-packages/matplotlib/pyplot.py:446\u001b[0m, in \u001b[0;36mshow\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    402\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    403\u001b[0m \u001b[38;5;124;03mDisplay all open figures.\u001b[39;00m\n\u001b[1;32m    404\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    443\u001b[0m \u001b[38;5;124;03mexplicitly there.\u001b[39;00m\n\u001b[1;32m    444\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    445\u001b[0m _warn_if_gui_out_of_main_thread()\n\u001b[0;32m--> 446\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_get_backend_mod\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshow\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/dlcourse-BfLxQsIA-py3.11/lib/python3.11/site-packages/matplotlib_inline/backend_inline.py:98\u001b[0m, in \u001b[0;36mshow\u001b[0;34m(close, block)\u001b[0m\n\u001b[1;32m     95\u001b[0m show\u001b[38;5;241m.\u001b[39m_to_draw \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     96\u001b[0m \u001b[38;5;66;03m# only call close('all') if any to close\u001b[39;00m\n\u001b[1;32m     97\u001b[0m \u001b[38;5;66;03m# close triggers gc.collect, which can be slow\u001b[39;00m\n\u001b[0;32m---> 98\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m close \u001b[38;5;129;01mand\u001b[39;00m Gcf\u001b[38;5;241m.\u001b[39mget_all_fig_managers():\n\u001b[1;32m     99\u001b[0m     matplotlib\u001b[38;5;241m.\u001b[39mpyplot\u001b[38;5;241m.\u001b[39mclose(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mall\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "img = training_set[2].detach().numpy()\n",
    "plt.imshow(img)\n",
    "plt.show(img)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dlcourse-BfLxQsIA-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
