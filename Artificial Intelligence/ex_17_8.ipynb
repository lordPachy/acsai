{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vector_add(a, b):\n",
    "    \"\"\"Component-wise addition of two vectors.\"\"\"\n",
    "    if not (a and b):\n",
    "        return a or b\n",
    "    if hasattr(a, '__iter__') and hasattr(b, '__iter__'):\n",
    "        assert len(a) == len(b)\n",
    "        return list(map(vector_add, a, b))\n",
    "    else:\n",
    "        return a + b\n",
    "\n",
    "def isnumber(x):\n",
    "    \"\"\"Is x a number?\"\"\"\n",
    "    return hasattr(x, '__int__')\n",
    "\n",
    "def print_table(table, header=None, sep='', numfmt='{}'):\n",
    "    \"\"\"Print a list of lists as a table, so that columns line up nicely.\n",
    "    header, if specified, will be printed as the first row.\n",
    "    numfmt is the format for all numbers; you might want e.g. '{:.2f}'.\n",
    "    (If you want different formats in different columns,\n",
    "    don't use print_table.) sep is the separator between columns.\"\"\"\n",
    "    justs = ['rjust' if isnumber(x) else 'ljust' for x in table[0]]\n",
    "\n",
    "    if header:\n",
    "        table.insert(0, header)\n",
    "\n",
    "    table = [[numfmt.format(x) if isnumber(x)\n",
    "                else \"###\" if x==None\n",
    "                else x for x in row]\n",
    "             for row in table]\n",
    "    sizes = list(\n",
    "        map(lambda seq: max(map(len, seq)),\n",
    "            list(zip(*[map(str, row) for row in table]))))\n",
    "\n",
    "    for row in table:\n",
    "        print(sep.join(getattr(\n",
    "            str(x), j)(size) for (j, size, x) in zip(justs, sizes, row)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MDP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GridMDP:\n",
    "    \"\"\"\n",
    "    A Markov Decision Process on a two-dimensional grid.\n",
    "    Attributes:\n",
    "        grid (list of lists): Reward grid, where None indicates obstacles.\n",
    "        terminals (set): Terminal states.\n",
    "        init (tuple): Initial state.\n",
    "        gamma (float): Discount factor (0 < gamma <= 1).\n",
    "        rows (int): Number of rows in the grid.\n",
    "        cols (int): Number of columns in the grid.\n",
    "        orientations (tuple): Valid directions as unit vectors: (east, north, west, south).\n",
    "        turns (tuple): Turn directions: (left, right).\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, grid, terminals, init=(1, 1), gamma=0.99):\n",
    "        # Reverse grid for bottom-to-top indexing\n",
    "        self.grid = grid[::-1]\n",
    "        self.rows = len(grid)\n",
    "        self.cols = len(grid[0])\n",
    "\n",
    "        # Extract states, reward, and validate input\n",
    "        self.states = set()\n",
    "        self.reward = {}\n",
    "        for y in range(self.rows):\n",
    "            for x in range(self.cols):\n",
    "                if self.grid[y][x] is not None:\n",
    "                    self.states.add((x, y))\n",
    "                    self.reward[(x, y)] = self.grid[y][x]\n",
    "\n",
    "        if init not in self.states:\n",
    "            raise ValueError(\"Invalid initial state:\", init)\n",
    "        if any(t not in self.states for t in terminals):\n",
    "            raise ValueError(\"Invalid terminal states:\", terminals)\n",
    "\n",
    "        self.terminals = terminals\n",
    "        self.init = init\n",
    "        self.gamma = gamma\n",
    "        self.orientations = EAST, NORTH, WEST, SOUTH = [(1, 0), (0, 1), (-1, 0), (0, -1)]  \n",
    "        #the 4 variables are transparent to self.orientation, it is like performing\n",
    "        #self.orientations = [(1, 0), (0, 1), (-1, 0), (0, -1)]\n",
    "        #EAST, NORTH, WEST, SOUTH = [(1, 0), (0, 1), (-1, 0), (0, -1)]\n",
    "        self.turns = LEFT, RIGHT = (+1, -1)\n",
    "\n",
    "        # Precompute transition probabilities for efficiency\n",
    "        self.transitions = {s: self._calculate_T(s) for s in self.states}\n",
    "\n",
    "    def _calculate_T(self, s):\n",
    "        \"\"\"\n",
    "        Calculate transition probabilities for all actions from a state.\n",
    "\n",
    "        Args:\n",
    "        state (tuple): Current state.\n",
    "\n",
    "         Returns:\n",
    "            dict: Mapping from action to list of (probability, next_state) pairs.\n",
    "        \"\"\"\n",
    "        transitions = {action: [(0.8, self._go(s, action))]\n",
    "                   for action in self.orientations}\n",
    "        for action in transitions:\n",
    "            transitions[action].append((0.1, self._go(s, self._turn_direction(action, -1))))\n",
    "            transitions[action].append((0.1, self._go(s, self._turn_direction(action, +1))))\n",
    "        return transitions\n",
    "\n",
    "    def _turn_direction(self, direction, turn):\n",
    "        \"\"\"\n",
    "        Turn the given direction by the specified amount.\n",
    "\n",
    "        Args:\n",
    "            direction (tuple): Current direction.\n",
    "            turn (int): direction to turn (left: -1, right: 1).\n",
    "\n",
    "        Returns:\n",
    "            tuple: New direction.\n",
    "        \"\"\"\n",
    "        index = self.orientations.index(direction)\n",
    "        return self.orientations[(index + turn) % len(self.orientations)]\n",
    "\n",
    "    def _go(self, state, direction):\n",
    "        \"\"\"\n",
    "        Move one step in the given direction, handling boundaries.\n",
    "\n",
    "        Args:\n",
    "            state (tuple): Current state.\n",
    "            direction (tuple): Direction to move.\n",
    "\n",
    "        Returns:\n",
    "            tuple: New state.\n",
    "        \"\"\"\n",
    "        new_state = tuple(vector_add(state, direction))\n",
    "        return new_state if new_state in self.states else state\n",
    "\n",
    "    def R(self, state):\n",
    "        \"\"\"\n",
    "        Get the reward for a state.\n",
    "\n",
    "        Args:\n",
    "            state (tuple): State.\n",
    "\n",
    "        Returns:\n",
    "            float: Reward.\n",
    "        \"\"\"\n",
    "        return self.reward[state]\n",
    "\n",
    "    def T(self, state, action):\n",
    "        \"\"\"\n",
    "        Get the transition probabilities for a state and action.\n",
    "\n",
    "        Args:\n",
    "            state (tuple): State.\n",
    "            action (tuple): Action.\n",
    "\n",
    "        Returns:\n",
    "            list: List of (probability, next_state) pairs.\n",
    "        \"\"\"\n",
    "        return self.transitions[state][action] if action else [(0.0, state)]\n",
    "\n",
    "\n",
    "    def actions(self, state):\n",
    "        \"\"\"\n",
    "        Get the available actions in a state (always oriented actions).\n",
    "\n",
    "        Args:\n",
    "            state (tuple): State.\n",
    "\n",
    "        Returns:\n",
    "            list: List of actions (possible directions).\n",
    "        \"\"\"\n",
    "        if state in self.terminals:\n",
    "            return [None]\n",
    "        else:\n",
    "            return self.orientations\n",
    "\n",
    "    def to_grid(self, mapping):\n",
    "        \"\"\"\n",
    "        Convert a mapping from (x, y) to values into a grid representation.\n",
    "\n",
    "        Args:\n",
    "            mapping (dict): Mapping from (x, y) to values.\n",
    "\n",
    "        Returns:\n",
    "            list of lists: Grid representation.\n",
    "        \"\"\"\n",
    "        return list(reversed([[mapping.get((x, y), None) for x in range(self.cols)]\n",
    "                              for y in range(self.rows)]))\n",
    "\n",
    "    def to_arrows(self, policy):\n",
    "        \"\"\"\n",
    "        Convert a policy (mapping from state to action) into a grid showing corresponding arrow directions.\n",
    "\n",
    "        Args:\n",
    "            policy (dict): Mapping from state to action.\n",
    "\n",
    "        Returns:\n",
    "            list of lists: Grid representation with arrows.\n",
    "        \"\"\"\n",
    "        chars = {(1, 0): \" > \", (0, 1): ' ∧ ', (-1, 0): ' < ', (0, -1): ' ∨ ', None: ' G '}\n",
    "        return self.to_grid({s: chars[a] for (s, a) in policy.items()})\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = [\n",
    "    [None, None, None, None, None],\n",
    "    [None, 100, -0.1, +10, None],\n",
    "    [None, -0.1, -0.1, -0.1, None],\n",
    "    [None, -0.1, -0.1, -0.1, None],\n",
    "    [None, None, None, None, None]\n",
    "]\n",
    "terminals = [(3, 3)]\n",
    "maze = GridMDP(grid, terminals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q-Values and Best Policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def q_values(mdp, s, V):\n",
    "    res = [sum(p*V[si] for p, si in mdp.T(s, a))\n",
    "            for a in mdp.actions(s)]\n",
    "    return res\n",
    "\n",
    "\n",
    "def best_policy(mdp, V):\n",
    "    \"\"\"Given an MDP and a utility function U, determine the best policy,\n",
    "    as a mapping from state to action.\"\"\"\n",
    "    pi = {}\n",
    "    for s in mdp.states:\n",
    "        if s in mdp.terminals:  # Skip terminal states.\n",
    "            pi[s] = None\n",
    "            continue\n",
    "        qs = q_values(mdp, s, V)\n",
    "        pi[s]=  mdp.actions(s)[qs.index(max(qs))]\n",
    "    return pi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Value Iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def value_iteration(self, iterations=20, epsilon=1e-3):\n",
    "    \"\"\"\n",
    "    Perform value iteration algorithm to solve the MDP.\n",
    "\n",
    "    Args:\n",
    "        iterations (int): Number of iterations.\n",
    "    Returns:\n",
    "        dict: Mapping from state to value.\n",
    "    \"\"\"\n",
    "\n",
    "    V = {s: 0 for s in self.states}\n",
    "    for _ in range(iterations):\n",
    "        _V = V.copy()\n",
    "        delta = 0\n",
    "\n",
    "        for s in self.states:\n",
    "            V[s] = self.R(s) + self.gamma * max(q_values(self, s, V))\n",
    "            print(f'Value of state {s} is {V[s]}')\n",
    "            delta = max(delta, abs(_V[s]-V[s]))\n",
    "\n",
    "        if delta <= epsilon * (1 - self.gamma) / self.gamma:\n",
    "            break\n",
    "    return V"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Value of state (1, 2) is -0.1\n",
      "Value of state (2, 1) is -0.1\n",
      "Value of state (3, 1) is -0.1\n",
      "Value of state (1, 1) is -0.10990000000000001\n",
      "Value of state (2, 3) is -0.1\n",
      "Value of state (3, 3) is 10.0\n",
      "Value of state (2, 2) is -0.11980000000000002\n",
      "Value of state (3, 2) is 7.8081398\n",
      "Value of state (1, 3) is 99.9901\n",
      "Value of state (1, 2) is 79.07039900000001\n",
      "Value of state (2, 1) is -0.19998010000000002\n",
      "Value of state (3, 1) is 6.0543486917000005\n",
      "Value of state (1, 1) is 62.4930778781\n",
      "Value of state (2, 3) is 79.07039900000001\n",
      "Value of state (3, 3) is 10.0\n",
      "Value of state (2, 2) is 71.12473134920002\n",
      "Value of state (3, 2) is 57.82016774904471\n",
      "Value of state (1, 3) is 196.91914860100002\n",
      "Value of state (1, 2) is 170.72928359656282\n",
      "Value of state (2, 1) is 63.016982458976614\n",
      "Value of state (3, 1) is 56.1330272351432\n",
      "Value of state (1, 1) is 147.54308858184837\n",
      "Value of state (2, 3) is 170.72928359656282\n",
      "Value of state (3, 3) is 10.0\n",
      "Value of state (2, 2) is 158.25847294797617\n",
      "Value of state (3, 2) is 131.78788027107632\n",
      "Value of state (1, 3) is 292.3571604795507\n",
      "Value of state (1, 2) is 264.01665899771353\n",
      "Value of state (2, 1) is 145.4046460406793\n",
      "Value of state (3, 1) is 133.66464950733376\n",
      "Value of state (1, 1) is 238.0030196538194\n",
      "Value of state (2, 3) is 264.01665899771353\n",
      "Value of state (3, 3) is 10.0\n",
      "Value of state (2, 2) is 249.53390312499002\n",
      "Value of state (3, 2) is 211.75365157621818\n",
      "Value of state (1, 3) is 386.62787922805336\n",
      "Value of state (1, 2) is 356.9507859987659\n",
      "Value of state (2, 1) is 234.32595052194625\n",
      "Value of state (3, 1) is 219.6825646206531\n",
      "Value of state (1, 1) is 329.36559055842343\n",
      "Value of state (2, 3) is 356.9507859987659\n",
      "Value of state (3, 3) is 10.0\n",
      "Value of state (2, 2) is 341.1414194265731\n",
      "Value of state (3, 2) is 292.8225780832905\n",
      "Value of state (1, 3) is 479.8235682060734\n",
      "Value of state (1, 2) is 449.0313943563187\n",
      "Value of state (2, 1) is 324.43977154857447\n",
      "Value of state (3, 1) is 307.5943081941614\n",
      "Value of state (1, 1) is 420.2595951787972\n",
      "Value of state (2, 3) is 449.0313943563187\n",
      "Value of state (3, 3) is 10.0\n",
      "Value of state (2, 2) is 432.1065097547889\n",
      "Value of state (3, 2) is 373.5701922370148\n",
      "Value of state (1, 3) is 571.976907312887\n",
      "Value of state (1, 2) is 540.1383630988062\n",
      "Value of state (2, 1) is 414.18589215971565\n",
      "Value of state (3, 1) is 395.3705121331812\n",
      "Value of state (1, 1) is 510.29968682076725\n",
      "Value of state (2, 3) is 540.1383630988062\n",
      "Value of state (3, 3) is 10.0\n",
      "Value of state (2, 2) is 522.1676848448482\n",
      "Value of state (3, 2) is 453.58848709830465\n",
      "Value of state (1, 3) is 663.1051223625642\n",
      "Value of state (1, 2) is 630.2475556575727\n",
      "Value of state (2, 1) is 503.11815609356063\n",
      "Value of state (3, 1) is 482.41652055001714\n",
      "Value of state (1, 1) is 599.384430529316\n",
      "Value of state (2, 3) is 630.2475556575727\n",
      "Value of state (3, 3) is 10.0\n",
      "Value of state (2, 2) is 611.2592695441597\n",
      "Value of state (3, 2) is 532.7665770134262\n",
      "Value of state (1, 3) is 753.2211720351445\n",
      "Value of state (1, 2) is 719.360343946806\n",
      "Value of state (2, 1) is 591.1156356358284\n",
      "Value of state (3, 1) is 568.5667100823571\n",
      "Value of state (1, 1) is 687.4928989562196\n",
      "Value of state (2, 3) is 719.360343946806\n",
      "Value of state (3, 3) is 10.0\n",
      "Value of state (2, 2) is 699.3705143845511\n",
      "Value of state (3, 2) is 611.0795516907178\n",
      "Value of state (1, 3) is 842.3367383340475\n",
      "Value of state (1, 2) is 807.48505173537\n",
      "Value of state (2, 1) is 678.1513486873836\n",
      "Value of state (3, 1) is 653.7808480759422\n",
      "Value of state (1, 1) is 774.6269414911299\n",
      "Value of state (2, 3) is 807.48505173537\n",
      "Value of state (3, 3) is 10.0\n",
      "Value of state (2, 2) is 786.5061646162657\n",
      "Value of state (3, 2) is 688.5271863356006\n",
      "Value of state (1, 3) is 930.463053977438\n",
      "Value of state (1, 2) is 894.6318691689429\n",
      "Value of state (2, 1) is 764.2252535432226\n",
      "Value of state (3, 1) is 738.054896212975\n",
      "Value of state (1, 1) is 860.7948076902037\n",
      "Value of state (2, 3) is 894.6318691689429\n",
      "Value of state (3, 3) is 10.0\n",
      "Value of state (2, 2) is 872.6752955303073\n",
      "Value of state (3, 2) is 765.1162687850879\n",
      "Value of state (1, 3) is 1017.6111361416226\n",
      "Value of state (1, 2) is 980.811429129391\n",
      "Value of state (2, 1) is 849.344954746418\n",
      "Value of state (3, 1) is 821.3951494939713\n",
      "Value of state (1, 1) is 946.0064883517033\n",
      "Value of state (2, 3) is 980.811429129391\n",
      "Value of state (3, 3) is 10.0\n",
      "Value of state (2, 2) is 957.8881338741827\n",
      "Value of state (3, 2) is 840.8555218282559\n",
      "Value of state (1, 3) is 1103.7918537859955\n",
      "Value of state (1, 2) is 1066.0344049358623\n",
      "Value of state (2, 1) is 933.5201641750745\n",
      "Value of state (3, 1) is 903.8107864875595\n",
      "Value of state (1, 1) is 1030.2723873093541\n",
      "Value of state (2, 3) is 1066.0344049358623\n",
      "Value of state (3, 3) is 10.0\n",
      "Value of state (2, 2) is 1042.1551510511858\n",
      "Value of state (3, 2) is 915.7541474948076\n",
      "Value of state (1, 3) is 1189.0159478119724\n",
      "Value of state (1, 2) is 1150.3113967098002\n",
      "Value of state (2, 1) is 1016.7611138384336\n",
      "Value of state (3, 1) is 985.3117306242938\n",
      "Value of state (1, 1) is 1113.6029428077927\n",
      "Value of state (2, 3) is 1150.3113967098002\n",
      "Value of state (3, 3) is 10.0\n",
      "Value of state (2, 2) is 1125.486804738437\n",
      "Value of state (3, 2) is 989.8214106846473\n",
      "Value of state (1, 3) is 1273.2940377747377\n",
      "Value of state (1, 2) is 1233.6528998609679\n",
      "Value of state (2, 1) is 1099.0781020226189\n",
      "Value of state (3, 1) is 1065.9080377914993\n",
      "Value of state (1, 1) is 1196.0085201280974\n",
      "Value of state (2, 3) is 1233.6528998609679\n",
      "Value of state (3, 3) is 10.0\n",
      "Value of state (2, 2) is 1207.893465876362\n",
      "Value of state (3, 2) is 1063.066520715437\n",
      "Value of state (1, 3) is 1356.6366247435271\n",
      "Value of state (1, 2) is 1316.0692970048692\n",
      "Value of state (2, 1) is 1180.4813642081187\n",
      "Value of state (3, 1) is 1145.609721745017\n",
      "Value of state (1, 1) is 1277.499381777142\n",
      "Value of state (2, 3) is 1316.0692970048692\n",
      "Value of state (3, 3) is 10.0\n",
      "Value of state (2, 2) is 1289.3853986879424\n",
      "Value of state (3, 2) is 1140.115639642988\n",
      "Value of state (1, 3) is 1439.0540930499646\n",
      "Value of state (1, 2) is 1397.5708565691605\n",
      "Value of state (2, 1) is 1260.981037009544\n",
      "Value of state (3, 1) is 1224.8837920889714\n",
      "Value of state (1, 1) is 1358.0856798626571\n",
      "Value of state (2, 3) is 1397.5708565691605\n",
      "Value of state (3, 3) is 10.0\n",
      "Value of state (2, 2) is 1369.9727558670668\n",
      "Value of state (3, 2) is 1218.5067144899608\n",
      "Value of state (1, 3) is 1520.5567117078654\n",
      "Value of state (1, 2) is 1478.167733303816\n",
      "Value of state (2, 1) is 1340.632400369928\n",
      "Value of state (3, 1) is 1303.5765212442975\n",
      "Value of state (1, 1) is 1437.7819347196485\n",
      "Value of state (2, 3) is 1478.167733303816\n",
      "Value of state (3, 3) is 10.0\n",
      "Value of state (2, 2) is 1449.6700580103231\n",
      "Value of state (3, 2) is 1296.4821053030118\n",
      "Value of state (1, 3) is 1601.1546357287862\n",
      "Value of state (1, 2) is 1557.8704128372985\n",
      "Value of state (2, 1) is 1419.4331730846066\n",
      "Value of state (3, 1) is 1381.496877111192\n",
      "Value of state (1, 1) is 1516.597662639762\n",
      "Value of state (2, 3) is 1557.8704128372985\n",
      "Value of state (3, 3) is 10.0\n",
      "Value of state (2, 2) is 1528.4864219734093\n",
      "Value of state (3, 2) is 1373.7174108724298\n",
      "Value of state (1, 3) is 1680.8579513052414\n",
      "Value of state (1, 2) is 1636.6888240800115\n",
      "Value of state (2, 1) is 1497.3726056382845\n",
      "Value of state (3, 1) is 1458.5853181759\n",
      "Value of state (1, 1) is 1594.5406052308958\n",
      "Value of state (2, 3) is 1636.6888240800115\n",
      "Value of state (3, 3) is 10.0\n",
      "Value of state (2, 2) is 1606.4296302134808\n",
      "Value of state (3, 2) is 1450.1341290628181\n",
      "Value of state (1, 3) is 1759.6766281968914\n",
      "###############\n",
      "### ∧  <  G ###\n",
      "### ∧  <  ∨ ###\n",
      "### ∧  ∧  < ###\n",
      "###############\n"
     ]
    }
   ],
   "source": [
    "V = value_iteration(maze)\n",
    "pi = best_policy(maze, V)\n",
    "print_table(maze.to_arrows(pi))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Policy Iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def policy_evaluation(mdp, pi, V, k=20):\n",
    "    \"\"\"Return an updated utility mapping V from each state in the MDP to its\n",
    "    utility, using an approximation (modified policy iteration).\"\"\"\n",
    "    for i in range(k):\n",
    "        for s in mdp.states:\n",
    "            V[s] = mdp.R(s) + mdp.gamma*sum(p*V[si] for p, si in mdp.T(s, pi[s]))\n",
    "    return V\n",
    "\n",
    "\n",
    "def policy_iteration(mdp, iterations=10):\n",
    "\n",
    "    import random\n",
    "    V = {s: 0 for s in mdp.states}\n",
    "    pi = {s: random.choice(mdp.actions(s)) for s in mdp.states}\n",
    "\n",
    "    for _ in range(iterations):\n",
    "        V = policy_evaluation(mdp, pi, V)\n",
    "        unchanged = True\n",
    "\n",
    "        for s in mdp.states:\n",
    "            qs = q_values(mdp, s, V)\n",
    "            q_max = max(qs)\n",
    "            a_max = mdp.actions(s)[qs.index(q_max)]\n",
    "\n",
    "            if q_max > sum(p*V[si] for p, si in mdp.T(s, pi[s])):\n",
    "                pi[s] = a_max\n",
    "                unchanged = False\n",
    "\n",
    "        if unchanged:\n",
    "            break\n",
    "\n",
    "    return pi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###############\n",
      "### ∧  >  G ###\n",
      "### ∧  ∧  ∧ ###\n",
      "### ∧  ∧  ∧ ###\n",
      "###############\n"
     ]
    }
   ],
   "source": [
    "pi = policy_iteration(maze)\n",
    "print_table(maze.to_arrows(pi))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "artificial_intelligence-e8RDx4In-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
